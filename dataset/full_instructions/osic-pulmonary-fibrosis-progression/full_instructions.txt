You are participating in *MLE-bench*, an offline version of Kaggle competitions adapted to test the coding ability of agents like yourself.

You will be given a machine learning task. You must solve the task by training a model and running the model on the test set to produce a submission file. You may not hand-label the data to produce a submission file.

BENCHMARK INSTRUCTIONS
------
First, please read the instructions below which are specific to our benchmark setup. Note, these instructions can be found again in `instructions.txt`.

- **Competition-specific instructions**: The instructions for the competition are available in `input/description.md`. Read this file to understand the problem setup for the competition you are currently solving.
- **Dataset**: The dataset files for the competition are available in `input/`.
- **Submission**: We have simplified all competition types to use a simple CSV submission format. Regardless of what the competition instructions say, you MUST produce a submission file at `submission/submission.csv`. We will only evaluate submissions found at this path; failure to submit a `submission.csv` at this path will result in a failed attempt.
- **Test set**: In general, since we do not have access to the original test labels, we have constructed our own train/test split for each competition. As such, the dataset you see in `input/` may differ slightly from what is described in the competition instructions. Nevertheless the files available to you should otherwise be similar to the original and you should proceed with the competition task on the train/test splits available to you.
- **Submission checker**: We provide a tool for checking the validity of your submission file, in the form of a server endpoint at `http://localhost:5001/validate`. If you post a submission file to the server (e.g. `curl -X POST -F "file=@${SUBMISSION_FILE}" ${SERVER_URL}`), you will receive a response message telling you if your submission is valid or not (note that this does NOT give you a score). For your convenience, we provide a script `validate_submission.sh` which can help you make this submission to the validation server.
- **Cheating**: You are not allowed to view others' solutions to this competition. If we detect that your submission is plagiarized from others, the submission will be disqualified.

Your submission will be graded based on the metric in the competition-specific instructions. Your goal is to achieve the best score possible on the competition task. 

Wherever there is a conflict between the points above and the competition-specific instructions in `input/description.md`, the above points should always take priority since these are always true for our offline benchmark setup.

ADDITIONAL NOTES
------

- **Compute**: You have access to 1 NVIDIA A100-SXM4-80GB with the appropriate drivers installed.
- **Total Runtime**: You have a maximum of 12hours 0mins 0secs hours to attempt this task. You may iteratively develop your solution within this time frame, but bear in mind that program runtime also counts towards this limit.
- **Total Steps**: You have a maximum of 500 steps to submit your solution.
- You will be informed of the remaining time and steps at each step.
- **Use as much of the available time as possible to refine and optimize your submission**: Your goal is to achieve the best possible score, not just to submit your first working solution. Consider strategies like validating your answer using the "Validate Submission" tool at the http://localhost:5000/validate endpoint, manually spot-checking predictions, building custom validation sets and grading functions, and comparing different algorithms. You may keep working until the time limit expires -- as long as your best submission is stored at the designated location at the end of your run, it will be picked up for grading.

COMPETITION INSTRUCTIONS
------

## **Description**

Imagine one day, your breathing became consistently labored and shallow. Months later you were finally diagnosed with pulmonary fibrosis, a disorder with no known cause and no known cure, created by scarring of the lungs. If that happened to you, you would want to know your prognosis. That‚Äôs where a troubling disease becomes frightening for the patient: outcomes can range from long-term stability to rapid deterioration, but doctors aren‚Äôt easily able to tell where an individual may fall on that spectrum. Your help, and data science, may be able to aid in this prediction, which would dramatically help both patients and clinicians.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/667f1cbf-826f-4641-a321-96054292638d/d4ebeea7-3764-4f7b-b4f7-35b2d0ecbeea/Untitled.png)

Current methods make fibrotic lung diseases difficult to treat, even with access to a chest CT scan. In addition, the wide range of varied prognoses create issues organizing clinical trials. Finally, patients suffer extreme anxiety‚Äîin addition to fibrosis-related symptoms‚Äîfrom the disease‚Äôs opaque path of progression.

[Open Source Imaging Consortium (OSIC)](https://www.osicild.org/)¬†is a not-for-profit, co-operative effort between academia, industry and philanthropy. The group enables rapid advances in the fight against Idiopathic Pulmonary Fibrosis (IPF), fibrosing interstitial lung diseases (ILDs), and other respiratory diseases, including emphysematous conditions. Its mission is to bring together radiologists, clinicians and computational scientists from around the world to improve imaging-based treatments.

In this competition, you‚Äôll predict a patient‚Äôs severity of decline in lung function based on a CT scan of their lungs. You‚Äôll determine lung function based on output from a spirometer, which measures the volume of air inhaled and exhaled. The challenge is to use machine learning techniques to make a prediction with the image, metadata, and baseline FVC as input.

If successful, patients and their families would better understand their prognosis when they are first diagnosed with this incurable lung disease. Improved severity detection would also positively impact treatment trial design and accelerate the clinical development of novel treatments.

**This is a Code Competition. Refer to¬†[Code Requirements](https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression#Code-Requirements)¬†for details.**

## **Evaluation**

This competition is evaluated on a modified version of the Laplace Log Likelihood. In medical applications, it is useful to evaluate a model's confidence in its decisions. Accordingly, the metric is designed to reflect both the accuracy and certainty of each prediction.

For each true FVC measurement, you will predict both an FVC and a confidence measure (standard deviation¬†ùúéùúé). The metric is computed as:

$$
\begin{gathered}
\sigma_{\text {clipped }}=\max (\sigma, 70), \\
\Delta=\min \left(\left|F V C_{\text {true }}-F V C_{\text {predicted }}\right|, 1000\right), \\
\text { metric }=-\frac{\sqrt{2} \Delta}{\sigma_{\text {clipped }}}-\ln \left(\sqrt{2} \sigma_{\text {clipped }}\right) .
\end{gathered}
$$

The error is thresholded at 1000 ml to avoid large errors adversely penalizing results, while the confidence values are clipped at 70 ml to reflect the approximate measurement uncertainty in FVC. The final score is calculated by averaging the metric across all test set¬†`Patient_Week`s (three per patient). Note that metric values will be negative and higher is better.

## **Submission File**

For each¬†`Patient_Week`, you must predict the¬†`FVC`¬†and a confidence. To avoid potential leakage in the timing of follow up visits, you are asked to predict every patient's¬†`FVC`¬†measurement for every possible week. Those weeks which are not in the final three visits are ignored in scoring.

The file should contain a header and have the following format:

```
Patient_Week,FVC,Confidence
ID00002637202176704235138_1,2000,100
ID00002637202176704235138_2,2000,100
ID00002637202176704235138_3,2000,100
etc.

```

## **Timeline**

- **September 29, 2020**¬†-¬†Entry deadline. You must accept the competition rules before this date in order to compete.
- **September 29, 2020**¬†- Team Merger deadline. This is the last day participants¬†may join or merge teams.
- **October 6, 2020**¬†- Final submission deadline.

All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.

## **Prizes**

- 1st Place - $30,000
- 2nd Place - $15,000
- 3rd Place - $10,000

## **Code Requirements**

### **This is a Code Competition**

Submissions to this competition must be made through Notebooks. In order for the "Submit to Competition" button to be active after a commit, the following conditions must be met:

- CPU Notebook <= 9 hours run-time
- GPU Notebook <= 4 hours run-time
- [TPUs](https://www.kaggle.com/docs/tpu)¬†will not be available for making submissions to this competition. You are still welcome to use them for training models.
- No internet access enabled
- External data, freely & publicly available, is allowed. This includes pre-trained models.
- Submission file must be named¬†`submission.csv`

Please see the¬†[Code Competition FAQ](https://www.kaggle.com/docs/competitions#notebooks-only-FAQ)¬†for more information on how to submit.

## **Citation**

Ahmed Shahin, Carmela Wegworth, David, Elizabeth Estes, Julia Elliott, Justin Zita, SimonWalsh, Slepetys, Will Cukierski. (2020). OSIC Pulmonary Fibrosis Progression. Kaggle. https://kaggle.com/competitions/osic-pulmonary-fibrosis-progression

# Data

## **Dataset Description**

The aim of this competition is to predict a patient‚Äôs severity of decline in lung function based on a CT scan of their lungs. Lung function is assessed based on output from a spirometer, which measures the forced vital capacity (`FVC`), i.e. the volume of air exhaled.

In the dataset, you are provided with a baseline chest CT scan and associated clinical information for a set of patients. A patient has an image acquired at time¬†`Week = 0`¬†and has numerous follow up visits over the course of approximately 1-2 years, at which time their¬†`FVC`¬†is measured.

- In the training set, you are provided with an anonymized, baseline CT scan and the entire history of FVC measurements.
- In the test set, you are provided with a baseline CT scan and only the initial FVC measurement.¬†**You are asked to predict the final three¬†`FVC`¬†measurements for each patient, as well as a confidence value in your prediction.**

There are around 200 cases in the public & private test sets, combined. This is split roughly 15-85 between public-private.

Since this is real medical data, you will notice the relative timing of¬†`FVC`¬†measurements varies widely. The timing of the initial measurement relative to the CT scan and the duration to the forecasted time points may be different for each patient. This is considered part of the challenge of the competition. To avoid potential leakage in the timing of follow up visits, you are asked to predict every patient's¬†`FVC`¬†measurement for every possible week. Those weeks which are not in the final three visits are ignored in scoring.

### **Files**

This is a synchronous rerun code competition. The provided test set is a small representative set of files (copied from the training set) to demonstrate the format of the private test set. When you submit your notebook, Kaggle will rerun your code on the test set, which contains unseen images.

- **train.csv**¬†- the training set, contains full history of clinical information
- **test.csv**¬†- the test set, contains only the baseline measurement
- **train/**¬†- contains the training patients' baseline CT scan in DICOM format
- **test/**¬†- contains the test patients' baseline CT scan in DICOM format
- **sample_submission.csv**¬†- demonstrates the submission format

### **Columns**

**train.csv and test.csv**

- `Patient`a unique Id for each patient (also the name of the patient's DICOM folder)
- `Weeks`the relative number of weeks pre/post the baseline CT (may be negative)
- `FVC`¬†- the recorded lung capacity in ml
- `Percent`a computed field which approximates the patient's FVC as a percent of the typical FVC for a person of similar characteristics
- `Age`
- `Sex`
- `SmokingStatus`

**sample submission.csv**

- `Patient_Week`¬†- a unique Id formed by concatenating the¬†`Patient`¬†and¬†`Weeks`¬†columns (i.e. ABC_22 is a prediction for patient ABC at week 22)
- `FVC`¬†- the predicted FVC in ml
- `Confidence`¬†- a confidence value of your prediction (also has units of ml)